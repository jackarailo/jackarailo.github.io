---
layout: post
active_link: Blog
title:  "Evaluating properties in London with LEGO blocks"
excerpt: "We'll dive into using Neural Networks as LEGO blocks to evaluate house listings for sale in London"
comments: true
date:   2019-04-15 00:10:32
---

We all know about the tremendous success of Deep Learning. Convolutional Neural Networks recognize images, Recurrent Neural Networks understand temporal patterns on speech and text, and Feed Forward Neural Networks are more and more used with structured data. For complex problems with data coming in different formats, CNNs have been glued together with RNNs to join their powers ([see NY Times article](https://www.nytimes.com/2014/11/18/science/researchers-announce-breakthrough-in-content-recognition-software.html)). How can we use this approach for real life problems? This post describes how to treat Neural Networks as LEGO blocks and estimate sale prices for houses in London by combining images, text, and structured features.

<div class="images">
  <img alt="LEGO NN" src="assets/posts/lego/lego.jpg" style="width: 100%;height: 60%">
  <div class="label">
        Neural Networks can be assembled like LEGO blocks to solve complex problems
  </div>
</div>

## Solving a real problem using LEGO Blocks

## The Problem

About 100,000 people move to London every year. That's more than 3 full double deckers per day or more than 1,000 buses a year! The demand for buying or renting properties is unmanageable and the task of finding an appropriate place to live stressful and time consuming. We'll look into building a recommendation system which ranks properties listed daily online. Can Machine Learning help us with this task?

## Machine Learning to the rescue

To consider ML for solving a problem:

* `A pattern has to exist` Photos, descriptions, and key features available online are expected to closely reflect the price/value of a property. These can also be combined with secondary features which provide further insights into the problem.
* `It has to be difficult to be approached analytically` Hard coding or Software 1.0 cannot find a clear solution to this task and no reasonable person should have the patience to review all online housing listings posted each day.
* `We have data` About 100,000 properties are being sold in London every year and as of today you can find more than 40,000 available properties for sale. Most of the data is online which makes it easy to access photos, descriptions and features such as location, address, postcode, number of bedrooms, house type and more. 

We've collected a dataset of more than 45,000 properties for sale in London. And obviously we have house prices. What can we do with it?

<div class="images">
  <img alt="LONDON SALES" src="assets/posts/lego/London-property-sales-volumes.png" style="width: 100%;height: 60%">
  <div class="label">
        A mid-sized city of houses changes hands every year in London
  </div>
</div>

### What model architecture to use?

* `images` - if we want to extract meaningful information out of photos our best bet is to use CNNs. The downside is that they take a long time to train. Luckily, the community has open-sourced pretrained models based on state-of-the-art architectures and we'll only need to finetune them for our task - thank you Pytorch :)
* `unstructured text` - for unstructured data with sequential format the easy choice is using RNNs with Long-Short Memory Cells
* `structured key features` - for structured data the safe options are Gradient Boosting algorithms, Random Forests, and Feed Forward Neural Networks

Apparently, there is merit in mixing different architectures to solve our problem. But how do can we construct a single model and train it on our task? All NN architectures mix up well together thanks to their training algorithm, [backpropagation](https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e). It is time to bring all the LEGO pieces together.

### LEGO Neural Network Architecture

Our input images for each listing are piped through a pretrained CNN (ResNet50) as a single batch. We only had to replace the final fully-connected layer with a new one. This is the only layer that we train (there is merit into going deeper but probably another time) and it will give us a set of 200-D representations, one for each image in the batch. The CNN outputs are passed sequentially (order picked at random) through an LSTM cell, and we only keep a final 200-D vector.

After pre-processing the descriptions in our listings we built a vocabulary of all the words in our train set. Each word is transformed to a 50-D embedding vector. The set of vectors of each listing are passed sequentially through a second RNN (one-layer LSTM cell) and again we extract the last 200-D vector.

Both of the above 200-D vectors are concatenated with key features, including number of bedrooms, property coordinates, and one-hot encoded house types. This new vector is passed through a 2-layer deep NN which outputs a price prediction. Predictions are compared with the actual listing prices and the Mean Squared Error is backpropagated through our LEGO Neural Network.

<div class="images">
  <img alt="LEGO NN" src="assets/posts/lego/lego_nn.png" style="width: 100%;height: 100%">
  <div class="label">
        Network LEGO architecture
  </div>
</div>

### How does it perform?

The Lego NN has been trained for 10 hours, one per epoch, on a mainstream laptop GPU ([Nvidia 1050 Ti](https://www.geforce.com/hardware/desktop-gpus/geforce-gtx-1050-ti/specifications)). A quick check of the predictions on the validation set show that the model performs reasonably well around the average London house price, however it commonly fails to capture rare cases of expensive house listings by a large margin. The metric used to evaluate house listings is based on the difference between price predictions and actual prices; the lower the actual price compared to the prediction, the higher the ranking. 

Model has been tested on new listings posted on [rightmove](https://www.rightmove.com/). See below some of the houses ranked in the top 10 for each day ([full list here](https://jackarailo.github.io/housing-evaluator.html)):

* [7 bedroom semi-detached house for sale - St Marys Road, Harlesden, London](https://www.rightmove.co.uk/property-for-sale/property-76274351.html) - the model overestimates prices of houses with many bedrooms. No suprise that a 7 bedroom house costing £800,000 gets a high ranking.
* [2 bedroom flat for sale - Church Street, Lisson Grove, NW8](https://www.rightmove.co.uk/property-for-sale/property-61444548.html) - it understands that houses near central London are more expensive, so it didn't expect a £580,000 2 bed flat in Lisson Grove. Also photos look really good.
* [2 bedroom flat for sale - Adelaide Road, Swiss Cottage, NW3](https://www.rightmove.co.uk/property-for-sale/property-54277248.html) - a low priced 2 bed in Swiss cottage gets a high ranking. Unfortunately the model doesn't see that the lease date expires in just 13 years (not passed as model input).
* [2 bedroom penthouse for sale - Ironmonger Row, Clerkenwell](https://www.rightmove.co.uk/property-for-sale/property-68174857.html) - a 2 bed house in Clerkenwell right next to Old street gets a high ranking despite the £700,000 listing price. Makes sense to me.
* [2 bedroom apartment for sale - Wandsworth Exchange, Wandsworth High Street, London, SW18 2PT](https://www.rightmove.co.uk/property-for-sale/property-80829404.html) - a really low priced listing, however the model missed that it is offered with shared ownership (wasn't passed as model input).

### Takeaway

When our input data come in different formats we should definitely consider using Lego NNs. By stacking different architectures together we tune them for the same task, and we avoid the potential accumulation of errors when networks are trained separately. Note this is by no means the only or always the best approach - keeping our models simpler and separate makes total sense especially when we don't have enough data and we want to reduce variance.

Machine Learning is an iterative process. By reviewing our model performance we can look into making more robust. Apparently for our task, leasehold expiry dates or shared ownership can play a large role on house prices so we should both include them in our model features.

### Acknowledgements and References

Thanks for reading this post. I'd be happy to exchange ideas, improve this article, or assist if you have any questions or comments - please get in touch <jackarailo@gmail.com>.

1. [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)
1. [Plumplot London Property Sales Volumes](http://www.plumplot.co.uk/London-property-sales.html)
1. [UK Gov housing data](https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads)
1. [Torchvision](https://pytorch.org/docs/stable/torchvision/index.html)
1. [Draw.io](https://www.draw.io/)
